{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"D:/CSE519/Project/fixed_train.csv\",sep='\\t')\n",
    "df_test=pd.read_csv(\"D:/CSE519/Project/fixed_test.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17924, 51)\n",
      "(4482, 51)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'weekid', 'week_position', 'song', 'performer', 'songid', 'instance', 'previous_week_position', 'rank', 'weeks_on_chart', 'year', 'week', 'jump_time', 'max_jump_duration', 'strict_rule', 'lenient_rule', 'all_time_greatest_artist', 'artist_died', 'christmas', 'church', 'classical', 'in_commercials', 'concerts', 'easter', 'fourth_of_july', 'funerals', 'graduations', 'grammys', 'halloween', 'in_movie_clueless', 'in_movies', 'in_plays', 'in_tv_shows', 'karaoke', 'lullabies', 'mtv_awards', 'phone_call', 'politicians', 'sporting_events', 'tv_show_theme', 'weddings', 'won_oscars', 'wordcup', 'popularity', 'diff_year', 'adjusted_diff_year', 'log_rank', 'log_reverse_rank', 'log_weeks_on_chart', 'log_jump_time', 'log_max_duration']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['popularity','url','instance','week','lenient_rule']\n",
    "df_train.drop(columns_to_drop, inplace=True,axis=1)    \n",
    "df_train.rename(columns={\"strict_rule\":\"popularity\"},inplace=True) \n",
    "df_train_valid=df_train.loc[df_train['popularity']>0]\n",
    "\n",
    "\n",
    "df_test.drop(columns_to_drop, inplace=True,axis=1)    \n",
    "df_test.rename(columns={\"strict_rule\":\"popularity\"},inplace=True) \n",
    "df_test_valid=df_test.loc[df_test['popularity']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logPopularity=np.log(df_train_valid['popularity'])\n",
    "df_train_valid.insert(0,'logPopularity', train_logPopularity)\n",
    "df_train=df_train_valid\n",
    "\n",
    "test_logPopularity=np.log(df_test_valid['popularity'])\n",
    "df_test_valid.insert(0,'logPopularity', test_logPopularity)\n",
    "df_test=df_test_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logPopularity', 'weekid', 'week_position', 'song', 'performer', 'songid', 'previous_week_position', 'rank', 'weeks_on_chart', 'year', 'jump_time', 'max_jump_duration', 'popularity', 'all_time_greatest_artist', 'artist_died', 'christmas', 'church', 'classical', 'in_commercials', 'concerts', 'easter', 'fourth_of_july', 'funerals', 'graduations', 'grammys', 'halloween', 'in_movie_clueless', 'in_movies', 'in_plays', 'in_tv_shows', 'karaoke', 'lullabies', 'mtv_awards', 'phone_call', 'politicians', 'sporting_events', 'tv_show_theme', 'weddings', 'won_oscars', 'wordcup', 'diff_year', 'adjusted_diff_year', 'log_rank', 'log_reverse_rank', 'log_weeks_on_chart', 'log_jump_time', 'log_max_duration']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  random_forest_machine_learning(df_train, df_test,feature_to_keep, max_depth=2, random_state=0, n_estimators=100):\n",
    "    X=np.array(df_train[feature_to_keep].values)\n",
    "    print(X.shape)\n",
    "    y=np.array(df_train['logPopularity'].values)\n",
    "    print(y.shape)\n",
    "    regr = RandomForestRegressor(max_depth=max_depth, random_state=0,n_estimators=100)\n",
    "    regr.fit(X, y)\n",
    "    RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "    print(regr.feature_importances_)\n",
    "    X_test=np.array(df_test[feature_to_keep].values)\n",
    "    pred_test=regr.predict(X_test)\n",
    "    df_test.insert(df_test.shape[1], column='pred_randomForest', value=np.exp(pred_test) ) \n",
    "    \n",
    "    pred_train=regr.predict(X)\n",
    "    df_train.insert(df_train.shape[1], column='pred_randomForest', value=np.exp(pred_train) )\n",
    "    \n",
    "    test_error=np.abs(df_test['pred_randomForest']-df_test['popularity'])\n",
    "    test_error_square=np.square(df_test['pred_randomForest']-df_test['popularity'])\n",
    "    mean_absolute_error_test=np.sum(test_error)/test_error.size\n",
    "    MSE_test=np.sum(test_error_square)/test_error_square.size\n",
    "    print(\"test mean absolute error is \"+ str(mean_absolute_error_test))\n",
    "    print(\"test MSE is \"+ str(MSE_test))\n",
    "    \n",
    "    train_error=np.abs(df_train['pred_randomForest']-df_train['popularity'])\n",
    "    train_error_square=np.square(df_train['pred_randomForest']-df_train['popularity'])\n",
    "    mean_absolute_error_train=np.sum(train_error)/train_error.size\n",
    "    MSE_train=np.sum(train_error_square)/train_error_square.size\n",
    "    print(\"train mean absolute error is \"+ str(mean_absolute_error_train))\n",
    "    print(\"test MSE is \"+ str(MSE_train))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####----------------------errors_BY_YEAR-----------------------------#######\n",
    "#     mean_absolute_error= np.abs(df_test['pred_randomForest']-df_test['popularity'])\n",
    "    \n",
    "#     print (\"year error for test_case \")\n",
    "#     year_array=[]\n",
    "#     mean_square_error_array=[]\n",
    "#     mean_absolute_error_array=[]\n",
    "#     test_yearGroup=df_test.groupby('year')\n",
    "#     for idx, group in test_yearGroup:\n",
    "#         error_array=np.array(group['pred_randomForest']-group['popularity'])\n",
    "#         mean_square_error=np.sum(np.square(error_array))/error_array.size\n",
    "#         mean_abs_error=np.absolute(error_array)\n",
    "#         mean_absolute_error=np.sum(mean_abs_error)/mean_abs_error.size\n",
    "#         year_array.append(idx)\n",
    "#         mean_square_error_array.append(mean_square_error)\n",
    "#         mean_absolute_error_array.append(mean_absolute_error)\n",
    "#         print(\"mean absolute error in year \"+ str(idx)+ \" is \" + str(mean_absolute_error) )\n",
    "#         print(\"mean square error in year \"+ str(idx )+ \" is \"+ str(mean_square_error))\n",
    "    \n",
    "#     print (\"year error for train_case \")\n",
    "#     Train_year_array=[]\n",
    "#     Train_mean_square_error_array=[]\n",
    "#     Trainmean_absolute_error_array=[]\n",
    "#     train_yearGroup=df_train.groupby('year')\n",
    "#     for idx, group in train_yearGroup:\n",
    "#         error_array=np.array(group['pred_randomForest']-group['popularity'])\n",
    "#         mean_square_error=np.sum(np.square(error_array))/error_array.size\n",
    "#         mean_abs_error=np.absolute(error_array)\n",
    "#         mean_absolute_error=np.sum(mean_abs_error)/mean_abs_error.size\n",
    "#         year_array.append(idx)\n",
    "#         Train_mean_square_error_array.append(mean_square_error)\n",
    "#         Train_mean_absolute_error_array.append(mean_absolute_error)\n",
    "#         print(\"mean absolute error in year \"+ str(idx)+ \" is \" + str(mean_absolute_error) )\n",
    "#         print(\"mean square error in year \"+ str(idx )+ \" is \"+ str(mean_square_error))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(df_train, df_test,feature_to_keep, random_state=0, n_estimators=100):\n",
    "    X=np.array(df_train[feature_to_keep].values)\n",
    "    y=np.array(df_train['logPopularity'].values)    \n",
    "    \n",
    "    regr = DecisionTreeRegressor(max_depth=5)\n",
    "    regr.fit(X, y)\n",
    "        \n",
    "    X_test=np.array(df_test[feature_to_keep].values)\n",
    "    \n",
    "    pred_test=regr.predict(X_test)    \n",
    "    pred_train=regr.predict(X)\n",
    "   \n",
    "    df_test.insert(df_test.shape[1], column='pred_decision_tree', value=np.exp(pred_test) )    \n",
    "    df_train.insert(df_train.shape[1], column='pred_decision_tree', value=np.exp(pred_train) )\n",
    "    \n",
    "    test_error=np.abs(df_test['pred_decision_tree']-df_test['popularity'])\n",
    "    test_error_square=np.square(df_test['pred_decision_tree']-df_test['popularity'])\n",
    "    mean_absolute_error_test=np.sum(test_error)/test_error.size\n",
    "    MSE_test=np.sum(test_error_square)/test_error_square.size\n",
    "    print(\"test mean absolute error is \"+ str(mean_absolute_error_test))\n",
    "    print(\"test MSE is \"+ str(MSE_test))\n",
    "    \n",
    "    train_error=np.abs(df_train['pred_decision_tree']-df_train['popularity'])\n",
    "    train_error_square=np.square(df_train['pred_decision_tree']-df_train['popularity'])\n",
    "    mean_absolute_error_train=np.sum(train_error)/train_error.size\n",
    "    MSE_train=np.sum(train_error_square)/train_error_square.size\n",
    "    print(\"train mean absolute error is \"+ str(mean_absolute_error_train))\n",
    "    print(\"test MSE is \"+ str(MSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean absolute error is 11.131726151053858\n",
      "test MSE is 202.61830268338468\n",
      "train mean absolute error is 11.011038903257328\n",
      "test MSE is 199.34819591329\n"
     ]
    }
   ],
   "source": [
    "feature_to_keep=['log_reverse_rank','log_weeks_on_chart','diff_year']\n",
    "decision_tree(df_train, df_test,feature_to_keep, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_neighbor(df_train, df_test,feature_to_keep):\n",
    "    neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "    X=np.array(df_train[feature_to_keep].values)\n",
    "    y=np.array(df_train['logPopularity'].values)   \n",
    "    neigh.fit(X, y)   \n",
    "    KNeighborsRegressor(...)\n",
    "    \n",
    "    X_test=np.array(df_test[feature_to_keep].values)\n",
    "    \n",
    "    pred_test=neigh.predict(X_test)    \n",
    "    pred_train=neigh.predict(X)\n",
    "   \n",
    "    df_test.insert(df_test.shape[1], column='pred_KNN_neighbor', value=np.exp(pred_test) )    \n",
    "    df_train.insert(df_train.shape[1], column='pred_KNN_neighbor', value=np.exp(pred_train) )\n",
    "    \n",
    "    test_error=np.abs(df_test['pred_KNN_neighbor']-df_test['popularity'])\n",
    "    test_error_square=np.square(df_test['pred_KNN_neighbor']-df_test['popularity'])\n",
    "    mean_absolute_error_test=np.sum(test_error)/test_error.size\n",
    "    MSE_test=np.sum(test_error_square)/test_error_square.size\n",
    "    print(\"test mean absolute error is \"+ str(mean_absolute_error_test))\n",
    "    print(\"test MSE is \"+ str(MSE_test))\n",
    "    \n",
    "    train_error=np.abs(df_train['pred_KNN_neighbor']-df_train['popularity'])\n",
    "    train_error_square=np.square(df_train['pred_KNN_neighbor']-df_train['popularity'])\n",
    "    mean_absolute_error_train=np.sum(train_error)/train_error.size\n",
    "    MSE_train=np.sum(train_error_square)/train_error_square.size\n",
    "    print(\"train mean absolute error is \"+ str(mean_absolute_error_train))\n",
    "    print(\"test MSE is \"+ str(MSE_train))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean absolute error is 12.675383765536857\n",
      "test MSE is 270.8679961201618\n",
      "train mean absolute error is 7.358567296621001\n",
      "test MSE is 101.01327569639191\n"
     ]
    }
   ],
   "source": [
    "feature_to_keep=['log_reverse_rank','log_weeks_on_chart','diff_year']\n",
    "KNN_neighbor(df_train, df_test,feature_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No new feature and Non-log feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12743, 3)\n",
      "(12743,)\n",
      "[0.02401118 0.37801308 0.59797573]\n",
      "test mean absolute error is 12.90053229336903\n",
      "test MSE is 254.66648173359212\n",
      "train mean absolute error is 12.791295123832372\n",
      "test MSE is 253.29509586080496\n"
     ]
    }
   ],
   "source": [
    "feature_to_keep=['log_reverse_rank','log_weeks_on_chart','diff_year']\n",
    "random_forest_machine_learning(df_train, df_test,feature_to_keep, max_depth=3, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest by rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12743, 4)\n",
      "(12743,)\n",
      "[0.0161884  0.37801308 0.59797573 0.00782278]\n",
      "test mean absolute error is 12.900532293369025\n",
      "test MSE is 254.66648173359215\n",
      "train mean absolute error is 12.791295123832372\n",
      "test MSE is 253.295095860805\n"
     ]
    }
   ],
   "source": [
    "feature_to_keep=['log_reverse_rank','log_weeks_on_chart','diff_year','rank']\n",
    "# random_forest_machine_learning(df_train, df_test,feature_to_keep, max_depth=3, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
