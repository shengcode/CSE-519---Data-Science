{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "import itertools\n",
    "import string\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment_Mode = True\n",
    "Permutation_Test = Experiment_Mode\n",
    "CSV_File = 'D:/CSE519/Project/billboard_w_new_features_v7.csv\"'\n",
    "Year = 2018\n",
    "Quarter = 4\n",
    "df_all = None\n",
    "df_train = None\n",
    "df_test = None\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_insert_feature(df, func = None, feature_name = None):\n",
    "    if not feature_name:\n",
    "        raise ('Empty feature')\n",
    "\n",
    "    new_data = df.apply(lambda x: func(x, feature_name), axis = 1)\n",
    "    df.insert(df.shape[1], feature_name, new_data)\n",
    "    \n",
    "def insert_feature(df, func = None, feature_name = None):\n",
    "    if not feature_name:\n",
    "        raise ('Empty feature')\n",
    "\n",
    "    new_data = df.apply(func, axis = 1)\n",
    "    df.insert(df.shape[1], feature_name, new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features for base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "adjusted_diff_time = {0: 0, 1: 0.25, 2: 0.5, 3: 0.75}\n",
    "def adjust_time_duration(month):\n",
    "    quarter = (month - 1)//3\n",
    "    return adjusted_diff_time[quarter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_year(row_data, year = Year):\n",
    "    return year - row_data['year']\n",
    "\n",
    "def adjusted_difference_year(row_data, year = Year):\n",
    "    return year + adjust_time_duration(Quarter) - row_data['year'] - adjust_time_duration(row_data['weekid'].month)\n",
    "\n",
    "def log_rank(row_data):\n",
    "    return np.log(row_data['rank'])\n",
    "\n",
    "def log_weeks_on_chart(row_data):\n",
    "    return np.log(row_data['weeks_on_chart'])\n",
    "\n",
    "def log_jump_time(row_data):\n",
    "    if row_data['jump_time'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(row_data['jump_time'])\n",
    "\n",
    "def log_max_duration(row_data):\n",
    "    if row_data['max_jump_duration'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(row_data['max_jump_duration'])\n",
    "    \n",
    "def log_popularity(row_data, rule):\n",
    "    if row_data[rule] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(row_data[rule])\n",
    "\n",
    "def insert_base_feature(df):\n",
    "    insert_feature(df, difference_year, 'diff_year')\n",
    "    insert_feature(df, adjusted_difference_year, 'adjusted_diff_year')\n",
    "    insert_feature(df, log_rank, 'log_rank')\n",
    "    insert_feature(df, log_weeks_on_chart, 'log_weeks_on_chart')\n",
    "    insert_feature(df, log_jump_time, 'log_jump_time')\n",
    "    insert_feature(df, log_max_duration, 'log_max_duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'D:/CSE519/Project/billboard_w_new_features_v7.csv\"' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-335d77e2af1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mExperiment_Mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf_billboard_100\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCSV_File\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf_billboard_100\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weekid'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_billboard_100\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweekid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf_billboard_100\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lenient_rule'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_billboard_100\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict_rule\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlenient_rule\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlenient_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf_billboard_100\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'popularity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_billboard_100\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlenient_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'D:/CSE519/Project/billboard_w_new_features_v7.csv\"' does not exist"
     ]
    }
   ],
   "source": [
    "if Experiment_Mode:\n",
    "    df_billboard_100 = pd.read_csv(CSV_File)\n",
    "    df_billboard_100['weekid'] = pd.to_datetime(df_billboard_100.weekid, infer_datetime_format = True)\n",
    "    df_billboard_100['lenient_rule'] = df_billboard_100.apply(lambda row: row.strict_rule if row.lenient_rule == 0 else row.lenient_rule, axis=1)\n",
    "    df_billboard_100['popularity'] = df_billboard_100.apply(lambda row: max(row.strict_rule, row.lenient_rule), axis=1)\n",
    "    peak_zero= df_billboard_100.loc[df_billboard_100['peak_position']==0]\n",
    "    peak=peak_zero['week_position'].min()\n",
    "    rows_to_change = df_billboard_100['peak_position'] == 0\n",
    "    df_billboard_100.loc[rows_to_change, 'peak_position'] = peak\n",
    "    df_billboard_100.rename(columns={\"peak_position\":\"rank\"},inplace=True) # rename the column name \n",
    "    df_billboard_100 = df_billboard_100.sort_values(\"weekid\", ascending=True)\n",
    "    df_billboard_100 = df_billboard_100.drop_duplicates([\"songid\"], keep='first')\n",
    "    df_all = df_billboard_100.loc[df_billboard_100['popularity']>0]\n",
    "    insert_base_feature(df_all)\n",
    "\n",
    "    df_train, df_test = train_test_split(df_all, test_size = test_size)\n",
    "else:\n",
    "    df_train = pd.read_csv(\"week_update_TrainV7.csv\")\n",
    "    df_test = pd.read_csv(\"week_update_TestV7.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>weekid</th>\n",
       "      <th>week_position</th>\n",
       "      <th>song</th>\n",
       "      <th>performer</th>\n",
       "      <th>songid</th>\n",
       "      <th>instance</th>\n",
       "      <th>previous_week_position</th>\n",
       "      <th>rank</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "      <th>...</th>\n",
       "      <th>strict_rule</th>\n",
       "      <th>lenient_rule</th>\n",
       "      <th>all_time_greatest_artist</th>\n",
       "      <th>popularity</th>\n",
       "      <th>diff_year</th>\n",
       "      <th>adjusted_diff_year</th>\n",
       "      <th>log_rank</th>\n",
       "      <th>log_weeks_on_chart</th>\n",
       "      <th>log_jump_time</th>\n",
       "      <th>log_max_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123256</th>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1958-0...</td>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>14</td>\n",
       "      <td>If Dreams Came True</td>\n",
       "      <td>Pat Boone</td>\n",
       "      <td>If Dreams Came TruePat Boone</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>59.75</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155393</th>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1958-0...</td>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>18</td>\n",
       "      <td>Little Star</td>\n",
       "      <td>The Elegants</td>\n",
       "      <td>Little StarThe Elegants</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>59.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109532</th>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1958-0...</td>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>97</td>\n",
       "      <td>I Believe In You</td>\n",
       "      <td>Robert &amp; Johnny</td>\n",
       "      <td>I Believe In YouRobert &amp; Johnny</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>59.75</td>\n",
       "      <td>4.532599</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79442</th>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1958-0...</td>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>15</td>\n",
       "      <td>For Your Precious Love</td>\n",
       "      <td>Jerry Butler and The Impressions</td>\n",
       "      <td>For Your Precious LoveJerry Butler and The Imp...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>59.75</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79380</th>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1958-0...</td>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>62</td>\n",
       "      <td>For Your Love</td>\n",
       "      <td>Ed Townsend</td>\n",
       "      <td>For Your LoveEd Townsend</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>59.75</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url     weekid  \\\n",
       "123256  http://www.billboard.com/charts/hot-100/1958-0... 1958-08-02   \n",
       "155393  http://www.billboard.com/charts/hot-100/1958-0... 1958-08-02   \n",
       "109532  http://www.billboard.com/charts/hot-100/1958-0... 1958-08-02   \n",
       "79442   http://www.billboard.com/charts/hot-100/1958-0... 1958-08-02   \n",
       "79380   http://www.billboard.com/charts/hot-100/1958-0... 1958-08-02   \n",
       "\n",
       "        week_position                    song  \\\n",
       "123256             14     If Dreams Came True   \n",
       "155393             18             Little Star   \n",
       "109532             97        I Believe In You   \n",
       "79442              15  For Your Precious Love   \n",
       "79380              62           For Your Love   \n",
       "\n",
       "                               performer  \\\n",
       "123256                         Pat Boone   \n",
       "155393                      The Elegants   \n",
       "109532                   Robert & Johnny   \n",
       "79442   Jerry Butler and The Impressions   \n",
       "79380                        Ed Townsend   \n",
       "\n",
       "                                                   songid  instance  \\\n",
       "123256                       If Dreams Came TruePat Boone         1   \n",
       "155393                            Little StarThe Elegants         1   \n",
       "109532                    I Believe In YouRobert & Johnny         1   \n",
       "79442   For Your Precious LoveJerry Butler and The Imp...         1   \n",
       "79380                            For Your LoveEd Townsend         1   \n",
       "\n",
       "        previous_week_position  rank  weeks_on_chart        ...         \\\n",
       "123256                     NaN    12              10        ...          \n",
       "155393                     NaN     1              17        ...          \n",
       "109532                     NaN    93               2        ...          \n",
       "79442                      NaN    15               5        ...          \n",
       "79380                      NaN    62               1        ...          \n",
       "\n",
       "        strict_rule  lenient_rule  all_time_greatest_artist  popularity  \\\n",
       "123256            0            22                         0          22   \n",
       "155393            0            35                         0          35   \n",
       "109532            0             4                         0           4   \n",
       "79442             0            42                         0          42   \n",
       "79380             0            20                         0          20   \n",
       "\n",
       "        diff_year  adjusted_diff_year  log_rank  log_weeks_on_chart  \\\n",
       "123256         60               59.75  2.484907            2.302585   \n",
       "155393         60               59.75  0.000000            2.833213   \n",
       "109532         60               59.75  4.532599            0.693147   \n",
       "79442          60               59.75  2.708050            1.609438   \n",
       "79380          60               59.75  4.127134            0.000000   \n",
       "\n",
       "        log_jump_time  log_max_duration  \n",
       "123256            0.0               0.0  \n",
       "155393            0.0               0.0  \n",
       "109532            0.0               0.0  \n",
       "79442             0.0               0.0  \n",
       "79380             0.0               0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features for advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_feature(row_data, feature_name = None):\n",
    "    if not feature_name:\n",
    "        raise ('Empty feature')\n",
    "\n",
    "    songid = row_data['song']\n",
    "    \n",
    "    if df_features[feature].loc[df_features[feature]['song'] == songid].shape[0] > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model I\n",
    "$popularity = rank C_t^{\\Delta t}$\n",
    "\n",
    "$\\log(popularity) = \\log(rank) + \\Delta t \\log(C_{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bm1(train = df_train, test = df_test, x_features = None, y_feature = None, intercept = True, full_info = False):\n",
    "    precision = ':.4f'\n",
    "    x_train = train[x_features].values\n",
    "    y_train = train[y_feature].values\n",
    "    log_y_train = train.apply(lambda row: -row['log_rank'] if row[y_feature] == 0 else np.log(row[y_feature]) - row['log_rank'], axis = 1).values\n",
    "    x_test = test[x_features].values\n",
    "    y_test = test[y_feature].values\n",
    "    log_y_test = test.apply(lambda row: -row['log_rank'] if row[y_feature] == 0 else np.log(row[y_feature]) - row['log_rank'], axis = 1).values\n",
    "    \n",
    "    regr = linear_model.LinearRegression()  \n",
    "    print(type(x_train))\n",
    "    regr.fit(x_train.reshape(-1,1), log_y_train)\n",
    "    \n",
    "    log_y_test_pred = regr.predict(x_test.reshape(-1,1))\n",
    "    log_y_train_pred= regr.predict(x_train.reshape(-1,1))\n",
    "\n",
    "#     y_test_pred = pd.Series(log_y_test_pred).add(test['log_rank']).apply(lambda x: np.exp(x))\n",
    "#     y_train_pred = pd.Series(log_y_train_pred).add(train['log_rank']).apply(lambda x: np.exp(x))\n",
    "    \n",
    "    info = {'coef': regr.coef_, \\\n",
    "            'intercept': regr.intercept_, \\\n",
    "            'test': {'Log-MSE': mean_squared_error(log_y_test, log_y_test_pred), \\\n",
    "                     'Log-MAE': mean_absolute_error(log_y_test, log_y_test_pred), \\\n",
    "                     'Log-Variance': r2_score(log_y_test, log_y_test_pred)}, \\\n",
    "#                      'MSE': mean_squared_error(y_test, y_test_pred), \\\n",
    "#                      'MAE': mean_absolute_error(y_test, y_test_pred), \\\n",
    "#                      'Variance': r2_score(y_test, y_test_pred)},\\\n",
    "            'train': {'Log-MSE': mean_squared_error(log_y_train, log_y_train_pred), \\\n",
    "                     'Log-MAE': mean_absolute_error(log_y_train, log_y_train_pred), \\\n",
    "                     'Log-Variance': r2_score(log_y_train, log_y_train_pred)}}\n",
    "#                      'MSE': mean_squared_error(y_train, y_train_pred), \\\n",
    "#                      'MAE': mean_absolute_error(y_train, y_train_pred), \\\n",
    "#                      'Variance': r2_score(y_train, y_train_pred)}}\n",
    "\n",
    "    if full_info:\n",
    "        print('Coefficients: \\n', regr.coef_, end=' ')\n",
    "\n",
    "        if intercept:\n",
    "            print('Intercept: {:.5f}'.format(regr.intercept_))\n",
    "        else:\n",
    "            print('\\n')\n",
    "        print_str = '(Log MSE:{' + precision + '}, MSE:{' + precision + '},' + \\\n",
    "                    'Log MAE:{' + precision + '}, MAE:{' + precision + '},' + \\\n",
    "                    'Log Variance:{' + precision + '},' + 'Variance:{' + precision + '})' \n",
    "        print(\"        train case:\", end = ' ')\n",
    "        print(print_str.format(info['train']['Log-MSE'],\\\n",
    "                               info['train']['MSE'],\\\n",
    "                               info['train']['Log-MAE'],\\\n",
    "                               info['train']['MAE'],\\\n",
    "                               info['train']['Log-Variance'],\\\n",
    "                               info['train']['Variance']))\n",
    "        print(\"        test case:\", end = ' ')\n",
    "        print(print_str.format(info['test']['Log-MSE'],\\\n",
    "                               info['test']['MSE'],\\\n",
    "                               info['test']['Log-MAE'],\\\n",
    "                               info['test']['MAE'],\\\n",
    "                               info['test']['Log-Variance'],\\\n",
    "                               info['test']['Variance']))\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.01193829]), 'intercept': 0.58729359848843621, 'test': {'Log-MSE': 2.5475677115870932, 'Log-MAE': 1.2466241439843273, 'Log-Variance': 0.019274776425998397}, 'train': {'Log-MSE': 2.5985401026471138, 'Log-MAE': 1.2596212406818135, 'Log-Variance': 0.014902368895032936}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.0119407]), 'intercept': 0.58584758613833277, 'test': {'Log-MSE': 2.5478237583819947, 'Log-MAE': 1.2466955716987134, 'Log-Variance': 0.019176207289235858}, 'train': {'Log-MSE': 2.5985080860753413, 'Log-MAE': 1.2596236254744053, 'Log-Variance': 0.014914506267466376}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02012452]), 'intercept': 0.52640003956237136, 'test': {'Log-MSE': 2.8107869501720719, 'Log-MAE': 1.3014013671886207, 'Log-Variance': 0.048109100871394972}, 'train': {'Log-MSE': 2.814322245970923, 'Log-MAE': 1.3055387993130478, 'Log-Variance': 0.04371307643149891}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02014659]), 'intercept': 0.52443015507139568, 'test': {'Log-MSE': 2.8107657833521231, 'Log-MAE': 1.3014885380813896, 'Log-Variance': 0.048116269149756197}, 'train': {'Log-MSE': 2.8140187850478862, 'Log-MAE': 1.3054932397822374, 'Log-Variance': 0.043816190320794646}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02123114]), 'intercept': 0.73867549206659855, 'test': {'Log-MSE': 2.7446272213332397, 'Log-MAE': 1.2907678230171216, 'Log-Variance': 0.054412436838943146}, 'train': {'Log-MSE': 2.7553301973700002, 'Log-MAE': 1.2944717120934317, 'Log-Variance': 0.049398877258285956}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02125301]), 'intercept': 0.73655156536721611, 'test': {'Log-MSE': 2.744827686406031, 'Log-MAE': 1.2909227896463473, 'Log-Variance': 0.05434337198444994}, 'train': {'Log-MSE': 2.7550114038805358, 'Log-MAE': 1.2943997031321335, 'Log-Variance': 0.049508862424237021}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.01228995]), 'intercept': 0.59558608764167942, 'test': {'Log-MSE': 2.49051095990017, 'Log-MAE': 1.2266034116869207, 'Log-Variance': 0.017732633220546301}, 'train': {'Log-MSE': 2.6227809882686755, 'Log-MAE': 1.2683930640812238, 'Log-Variance': 0.015611502470506577}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.01227297]), 'intercept': 0.59355885859124324, 'test': {'Log-MSE': 2.4905231896126065, 'Log-MAE': 1.2265573131899976, 'Log-Variance': 0.017727809773621206}, 'train': {'Log-MSE': 2.6228609016991635, 'Log-MAE': 1.2684129163221438, 'Log-Variance': 0.015581509168693497}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02072096]), 'intercept': 0.5424574939035629, 'test': {'Log-MSE': 2.7795872117254472, 'Log-MAE': 1.2865445754639429, 'Log-Variance': 0.042811149957479366}, 'train': {'Log-MSE': 2.8276849744702663, 'Log-MAE': 1.312145602652093, 'Log-Variance': 0.045972187471798986}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02073582]), 'intercept': 0.54016314984732094, 'test': {'Log-MSE': 2.7794620213738441, 'Log-MAE': 1.2864888593355897, 'Log-Variance': 0.042854260966258662}, 'train': {'Log-MSE': 2.8274289709163343, 'Log-MAE': 1.3121515561643906, 'Log-Variance': 0.046058560074391575}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02167828]), 'intercept': 0.75063494737201819, 'test': {'Log-MSE': 2.7004859808716923, 'Log-MAE': 1.2700338854395732, 'Log-Variance': 0.050657454432936122}, 'train': {'Log-MSE': 2.7742166387730136, 'Log-MAE': 1.3035132743478213, 'Log-Variance': 0.051016765663161268}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02168771]), 'intercept': 0.74803626862454375, 'test': {'Log-MSE': 2.7004101668798728, 'Log-MAE': 1.2699866579136654, 'Log-Variance': 0.05068410646834498}, 'train': {'Log-MSE': 2.7740205595276772, 'Log-MAE': 1.3035028208386368, 'Log-Variance': 0.051083838981742402}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.01277518]), 'intercept': 0.61046603244899522, 'test': {'Log-MSE': 2.6197382405047476, 'Log-MAE': 1.2686210137417642, 'Log-Variance': 0.014076650657243506}, 'train': {'Log-MSE': 2.567187803582097, 'Log-MAE': 1.2515393418997345, 'Log-Variance': 0.017182614467942559}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.01276545]), 'intercept': 0.60857508500602553, 'test': {'Log-MSE': 2.6198713925573531, 'Log-MAE': 1.2686464871455481, 'Log-Variance': 0.014026539651629699}, 'train': {'Log-MSE': 2.5672156699000563, 'Log-MAE': 1.2515384320789353, 'Log-Variance': 0.017171946178804021}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.0206789]), 'intercept': 0.53936523070981235, 'test': {'Log-MSE': 2.8705640459090511, 'Log-MAE': 1.3191768205078238, 'Log-Variance': 0.041622910459671814}, 'train': {'Log-MSE': 2.7887004588159332, 'Log-MAE': 1.2977176453013459, 'Log-Variance': 0.046513841424002278}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02069317]), 'intercept': 0.53705361317000433, 'test': {'Log-MSE': 2.8704161669435493, 'Log-MAE': 1.3191928272248781, 'Log-Variance': 0.041672281875984041}, 'train': {'Log-MSE': 2.7884541278888029, 'Log-MAE': 1.2976913206452925, 'Log-Variance': 0.046598064571276909}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02187098]), 'intercept': 0.754337001657996, 'test': {'Log-MSE': 2.7849436108957444, 'Log-MAE': 1.3030364778198025, 'Log-Variance': 0.046745189718604307}, 'train': {'Log-MSE': 2.7380897064359919, 'Log-MAE': 1.2891120516399954, 'Log-Variance': 0.052651840892767532}}\n",
      "<class 'numpy.ndarray'>\n",
      "{'coef': array([-0.02188077]), 'intercept': 0.75171937749168705, 'test': {'Log-MSE': 2.784881894281682, 'Log-MAE': 1.3030227294407835, 'Log-Variance': 0.046766314620020233}, 'train': {'Log-MSE': 2.7378880482996997, 'Log-MAE': 1.2890866829211214, 'Log-Variance': 0.052721612333687218}}\n"
     ]
    }
   ],
   "source": [
    "# log_rank, log_weeks_on_chart, log_jump_time, log_max_duration, diff_year, adjusted_diff_year\n",
    "stats = {'strict_rule':{}, 'lenient_rule':{}, 'popularity':{}}\n",
    "for _ in range(3):\n",
    "    df_train, df_test = train_test_split(df_all, test_size = test_size)\n",
    "    \n",
    "    MAE = {'strict_rule':[], 'lenient_rule':[], 'popularity':[]}\n",
    "    for y_feature in ['strict_rule', 'lenient_rule', 'popularity']:\n",
    "        for x_features in ['diff_year', 'adjusted_diff_year']:\n",
    "            info = evaluate_bm1(train = df_train.loc[df_train[y_feature] > 0] , \\\n",
    "                                test = df_test.loc[df_test[y_feature] > 0], \\\n",
    "                                x_features = x_features, \\\n",
    "                                y_feature = y_feature, \\\n",
    "                                intercept = True, \\\n",
    "                                full_info = False)\n",
    "            print(info)\n",
    "#             MAE[y_feature].append([x_features, \\\n",
    "#                                    info['coef'], \\\n",
    "#                                    info['intercept'], \\\n",
    "#                                    info['train']['MAE'], \\\n",
    "#                                    info['train']['Variance'], \\\n",
    "#                                    info['test']['MAE'], \\\n",
    "#                                    info['test']['Variance']])\n",
    "\n",
    "#         local_info = min(MAE[y_feature],key=itemgetter(3))\n",
    "#         print(local_info[3:])\n",
    "#         x_features_str = ''.join(local_info[0])\n",
    "#         if x_features_str in stats[y_feature]:\n",
    "#             stats[y_feature][x_features_str] += 1\n",
    "#         else:\n",
    "#             stats[y_feature][x_features_str] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model II\n",
    "$\n",
    "\\text{popularity} = \\text{rank}^{C_r}(\\text{weeks_on_chart})^{C_w}(\\text{jump_time})^{C_j} (\\text{max_duration})^{C_m}e^{C_t \\Delta t}\n",
    "$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log(\\text{popularity}) =& C_r\\log(\\text{rank}) + C_w\\log(\\text{weeks_on_chart}) \\\\&+ C_j\\log(\\text{jump_time}) + C_m\\log(\\text{max_duration}) + {C_t \\Delta t}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_base_model(train = df_train, test = df_test, x_features = None, y_feature = None, intercept = True, full_info = False):\n",
    "    precision = ':.4f'\n",
    "    x_train = train[x_features].values\n",
    "    y_train = train[y_feature].values\n",
    "    log_y_train = train[y_feature].apply(lambda x: 0 if x == 0 else np.log(x)).values\n",
    "    x_test = test[x_features].values\n",
    "    y_test = test[y_feature].values\n",
    "    log_y_test = test[y_feature].apply(lambda x: 0 if x == 0 else np.log(x)).values\n",
    "    \n",
    "    regr = linear_model.LinearRegression(fit_intercept=intercept)  \n",
    "    \n",
    "    regr.fit(x_train, log_y_train)\n",
    "    \n",
    "    log_y_test_pred = regr.predict(x_test)\n",
    "    log_y_train_pred= regr.predict(x_train)\n",
    "\n",
    "    y_test_pred = pd.Series(log_y_test_pred).apply(lambda x: np.exp(x))\n",
    "    y_train_pred = pd.Series(log_y_train_pred).apply(lambda x: np.exp(x))\n",
    "    \n",
    "    info = {'coef': regr.coef_, \\\n",
    "            'intercept': regr.intercept_, \\\n",
    "            'test': {'Log-MSE': mean_squared_error(log_y_test, log_y_test_pred), \\\n",
    "                     'Log-MAE': mean_absolute_error(log_y_test, log_y_test_pred), \\\n",
    "                     'Log-Variance': r2_score(log_y_test, log_y_test_pred), \\\n",
    "                     'MSE': mean_squared_error(y_test, y_test_pred), \\\n",
    "                     'MAE': mean_absolute_error(y_test, y_test_pred), \\\n",
    "                     'Variance': r2_score(y_test, y_test_pred)},\\\n",
    "            'train': {'Log-MSE': mean_squared_error(log_y_train, log_y_train_pred), \\\n",
    "                     'Log-MAE': mean_absolute_error(log_y_train, log_y_train_pred), \\\n",
    "                     'Log-Variance': r2_score(log_y_train, log_y_train_pred), \\\n",
    "                     'MSE': mean_squared_error(y_train, y_train_pred), \\\n",
    "                     'MAE': mean_absolute_error(y_train, y_train_pred), \\\n",
    "                     'Variance': r2_score(y_train, y_train_pred)}}\n",
    "\n",
    "    if full_info:\n",
    "        print('Coefficients: \\n', regr.coef_, end=' ')\n",
    "\n",
    "        if intercept:\n",
    "            print('Intercept: {:.5f}'.format(regr.intercept_))\n",
    "        else:\n",
    "            print('\\n')\n",
    "        print_str = '(Log MSE:{' + precision + '}, MSE:{' + precision + '},' + \\\n",
    "                    'Log MAE:{' + precision + '}, MAE:{' + precision + '},' + \\\n",
    "                    'Log Variance:{' + precision + '},' + 'Variance:{' + precision + '})' \n",
    "        print(\"        train case:\", end = ' ')\n",
    "        print(print_str.format(info['train']['Log-MSE'],\\\n",
    "                               info['train']['MSE'],\\\n",
    "                               info['train']['Log-MAE'],\\\n",
    "                               info['train']['MAE'],\\\n",
    "                               info['train']['Log-Variance'],\\\n",
    "                               info['train']['Variance']))\n",
    "        print(\"        test case:\", end = ' ')\n",
    "        print(print_str.format(info['test']['Log-MSE'],\\\n",
    "                               info['test']['MSE'],\\\n",
    "                               info['test']['Log-MAE'],\\\n",
    "                               info['test']['MAE'],\\\n",
    "                               info['test']['Log-Variance'],\\\n",
    "                               info['test']['Variance']))\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(df_all['rank'].apply(lambda x: np.exp(x)), df_all['rank'])\n",
    "mean_absolute_error(df_all['rank'].apply(lambda x: np.exp(x)).apply(lambda x:np.log(x)),df_all['rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Feature Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['log_weeks_on_chart', 'log_jump_time', 'log_max_duration']\n",
    "features_set_w_dy = []\n",
    "features_set_w_ady = []\n",
    "\n",
    "for idx in range(len(features) + 1):\n",
    "    set_combinations = itertools.combinations(features, idx)\n",
    "    for subset in set_combinations:\n",
    "        features_set_w_dy.append(list(subset))\n",
    "        features_set_w_ady.append(list(subset))\n",
    "        features_set_w_dy[-1].extend(['log_rank', 'diff_year'])\n",
    "        features_set_w_ady[-1].extend(['log_rank', 'adjusted_diff_year'])\n",
    "\n",
    "if not Experiment_Mode:\n",
    "    print(len(features_set_w_dy))\n",
    "    for features_opt0, features_opt1 in zip (features_set_w_dy, features_set_w_ady):\n",
    "        print(features_opt0)\n",
    "        print(features_opt1, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_x_features = features_set_w_ady + features_set_w_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_rank, log_weeks_on_chart, log_jump_time, log_max_duration, diff_year, adjusted_diff_year\n",
    "stats = {'strict_rule':{}, 'lenient_rule':{}, 'popularity':{}}\n",
    "for _ in range(3):\n",
    "    df_train, df_test = train_test_split(df_all, test_size = test_size)\n",
    "    \n",
    "    MAE = {'strict_rule':[], 'lenient_rule':[], 'popularity':[]}\n",
    "    for y_feature in ['strict_rule', 'lenient_rule', 'popularity']:\n",
    "#         print('y features:', y_feature)\n",
    "#         print()\n",
    "        for x_features in possible_x_features:\n",
    "    #         print('    x features:', x_features)\n",
    "            info = evaluate_base_model(train = df_train.loc[df_train[y_feature] > 0] , \\\n",
    "                                       test = df_test.loc[df_test[y_feature] > 0], \\\n",
    "                                       x_features = x_features, \\\n",
    "                                       y_feature = y_feature, \\\n",
    "                                       intercept = True, \\\n",
    "                                       full_info = False)\n",
    "            MAE[y_feature].append([x_features, \\\n",
    "                                   info['coef'], \\\n",
    "                                   info['intercept'], \\\n",
    "                                   info['train']['MAE'], \\\n",
    "                                   info['train']['Variance'], \\\n",
    "                                   info['test']['MAE'], \\\n",
    "                                   info['test']['Variance']])\n",
    "#             if x_features == ['log_rank', 'diff_year'] or \\\n",
    "#                x_features == ['log_rank', 'adjusted_diff_year']:\n",
    "#                 print('base model:', \\\n",
    "#                       x_features, '\\n'\\\n",
    "#                       'coef:', info['coef'], info['intercept'], '\\n', \\\n",
    "#                       info['train']['MAE'], \\\n",
    "#                       info['train']['Variance'], \\\n",
    "#                       info['test']['MAE'], \\\n",
    "#                       info['test']['Variance'], '\\n')\n",
    "\n",
    "        local_info = min(MAE[y_feature],key=itemgetter(3))\n",
    "        x_features_str = ''.join(local_info[0])\n",
    "        if x_features_str in stats[y_feature]:\n",
    "            stats[y_feature][x_features_str] += 1\n",
    "        else:\n",
    "            stats[y_feature][x_features_str] = 1\n",
    "#         print('minimal error model:', \\\n",
    "#               local_info[0], '\\n', \\\n",
    "#               'coef:', local_info[1:3], '\\n', \\\n",
    "#               local_info[3:], '\\n')\n",
    "\n",
    "    #         print('\\n')\n",
    "    #     print('\\n')\n",
    "    # print(df_train['popularity'].values.shape)\n",
    "    # print(df_train['strict_rule'].apply(lambda x: 0 if x == 0 else np.log(x)).values.shape)\n",
    "    # list(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for major_key in stats.keys():\n",
    "    print(major_key)\n",
    "    for minor_key in stats[major_key].keys():\n",
    "        print(minor_key, stats[major_key][minor_key])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_insert_feature(df, func = None, feature_name = None):\n",
    "    if not feature_name:\n",
    "        raise ('Empty feature')\n",
    "\n",
    "    new_data = df.apply(lambda x: func(x, feature_name), axis = 1)\n",
    "    df.insert(df.shape[1], feature_name, new_data)\n",
    "    \n",
    "def insert_feature(df, func = None, feature_name = None):\n",
    "    if not feature_name:\n",
    "        raise ('Empty feature')\n",
    "\n",
    "    new_data = df.apply(func, axis = 1)\n",
    "    df.insert(df.shape[1], feature_name, new_data)\n",
    "\n",
    "def new_feature(row_data, feature_name = None):\n",
    "    if not feature_name:\n",
    "        raise ('Empty feature')\n",
    "\n",
    "    songid = row_data['song']\n",
    "    \n",
    "    if df_features[feature].loc[df_features[feature]['song'] == songid].shape[0] > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = {}\n",
    "csv_files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "for csv_file in csv_files:\n",
    "    if 'csv' in csv_file and 'songs' in csv_file:\n",
    "        feature = csv_file.split('.')[0]\n",
    "        df_features[feature] = pd.read_csv(csv_file)\n",
    "        df_features[feature]['songid'] = df_features[feature][['song', 'artist']].apply(lambda x: ''.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_features = {}\n",
    "csv_files = ['songs-used-in-movies.csv',\\\n",
    "            'songs-used-in-tv-shows.csv',\\\n",
    "            'songs-used-in-commercials.csv']\n",
    "for csv_file in csv_files:\n",
    "    feature = csv_file.split('.')[0]\n",
    "    df_features[feature] = pd.read_csv(csv_file)\n",
    "    df_features[feature]['songid'] = df_features[feature][['song', 'artist']].apply(lambda x: ''.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_features.keys():\n",
    "    advanced_insert_feature(df_train, new_feature, feature)\n",
    "    advanced_insert_feature(df_test, new_feature, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new fit feature\n",
    "for feature in df_features.keys():\n",
    "    new_feature = 'fit-' + feature\n",
    "    df_train[new_feature] = df_train.apply(lambda row: np.log(row[feature] + 1), axis=1)\n",
    "    df_test[new_feature] = df_test.apply(lambda row: np.log(row[feature] + 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['new_feature'] = df_train[list(df_features)].apply(lambda x: 1 if any(x) else 0, axis=1)\n",
    "df_test['new_feature'] = df_test[list(df_features)].apply(lambda x: 1 if any(x) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sum_feature'] = df_train[list(df_features)].apply(lambda x: np.log(sum(x)) if any(x) else 0, axis=1)\n",
    "df_test['sum_feature'] = df_test[list(df_features)].apply(lambda x: np.log(sum(x)) if any(x) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_weeks_on_charts'] = df_train['weeks_on_chart'].apply(lambda x: np.log(x))\n",
    "df_test['log_weeks_on_charts'] = df_test['weeks_on_chart'].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_jump_time'] = df_train['jump_time'].apply(lambda x: np.log(x**2) if x > 0 else 0)\n",
    "df_test['log_jump_time'] = df_test['jump_time'].apply(lambda x: np.log(x**2) if x > 0 else 0)\n",
    "df_train['log_max_jump_duration'] = df_train['max_jump_duration'].apply(lambda x: np.log(x**2) if x > 0 else 0)\n",
    "df_test['log_max_jump_duration'] = df_test['max_jump_duration'].apply(lambda x: np.log(x**2) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_features.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model -fit-movie, fit-tv-show, fit-commercials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_featured_model(train = df_train, test = df_test, x_features = None, y_feature = None, intercept = True, full_info = False):\n",
    "    x_train = train[x_features].values  \n",
    "    y_train = train[y_feature].values\n",
    "    x_test = test[x_features].values\n",
    "    y_test = test[y_feature].values\n",
    "    \n",
    "    regr = linear_model.LinearRegression(fit_intercept=intercept) # with intercept \n",
    "    regr.fit(x_train, y_train)\n",
    "    ytest_pred = regr.predict(x_test)\n",
    "    ytrain_pred=regr.predict(x_train)\n",
    "    \n",
    "    if full_info:\n",
    "        print('Coefficients: \\n', regr.coef_)\n",
    "        print('Intercept when fit_intercept=True : {:.5f}'.format(regr.intercept_))\n",
    "    \n",
    "    print(\"Mean squared error for test case is: %.3f\"% mean_squared_error(y_test, ytest_pred))\n",
    "    if full_info:\n",
    "        print('Variance score for test case is: %.3f' % r2_score(y_test, ytest_pred))\n",
    "    print(\"Mean squared error for train case is: %.3f\"% mean_squared_error(y_train, ytrain_pred))\n",
    "    if full_info:\n",
    "        print('Variance score for test case is: %.3f' % r2_score(y_train, ytrain_pred))\n",
    "\n",
    "# df_train_mid=df_train.assign(predictedlogP=pd.Series(ytrain_pred))\n",
    "# df_test_mid=df_test.assign(predictedlogP=pd.Series(ytest_pred))\n",
    "    \n",
    "# predict_train=df_train_mid.assign(predictedPopularity=pd.Series( np.exp(df_train_mid['predictedlogP'])))\n",
    "# predict_test=df_test_mid.assign(predictedPopularity=pd.Series( np.exp(df_test_mid['predictedlogP'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_features = ['fit-'+ feature for feature in df_features.keys()]\n",
    "print(fit_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1958\n",
    "end_year = 2005\n",
    "for rank in ['logRank']:\n",
    "    for pop in ['logPopularity','logNewPopularity']:\n",
    "        print(rank, pop)\n",
    "        \n",
    "\n",
    "        print('linear regression - base model')\n",
    "        evaluation_featured_model(train=df_train.loc[df_train.year.isin([start_year, end_year])], test=df_test, x_features=[rank, 'Y_year'], y_feature=pop)\n",
    "\n",
    "        print('\\nlinear regression - base model 1')\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])], test=df_test,x_features=[rank, 'Y_year', 'log_weeks_on_charts'], y_feature=pop)\n",
    "        \n",
    "        print('\\nlinear regression - base model 2')\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])],\\\n",
    "                                  test=df_test\\\n",
    "                                  ,x_features=[rank, 'Y_year', 'log_weeks_on_charts'],\\\n",
    "                                  y_feature=pop)\n",
    "        \n",
    "        print('\\nlinear regression - base model 3')\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])],\\\n",
    "                                  test=df_test,\\\n",
    "                                  x_features=[rank,\\\n",
    "                                              'Y_year',\\\n",
    "                                              'log_weeks_on_charts',\\\n",
    "                                              'log_jump_time'],\\\n",
    "                                  y_feature=pop)\n",
    "        \n",
    "        print('\\nlinear regression - base model 4')\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])],\\\n",
    "                                  test=df_test,\\\n",
    "                                  x_features=[rank,\\\n",
    "                                              'Y_year',\\\n",
    "                                              'log_weeks_on_charts',\\\n",
    "                                              'log_jump_time',\\\n",
    "                                              'log_max_jump_duration'],\\\n",
    "                                  y_feature=pop)\n",
    "        \n",
    "        print('\\nlinear regression - base model 4')\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])],\\\n",
    "                                  test=df_test,\\\n",
    "                                  x_features=[rank,\\\n",
    "                                              'Y_year',\\\n",
    "                                              'log_weeks_on_charts',\\\n",
    "                                              'log_jump_time',\\\n",
    "                                              'log_max_jump_duration',\\\n",
    "                                              'all_time_greatest_artist'],\\\n",
    "                                  y_feature=pop)\n",
    "        \n",
    "        print('\\nlinear regression - advanced model')\n",
    "        features = [rank, 'Y_year', 'log_weeks_on_charts', 'log_jump_time', 'log_max_jump_duration']\n",
    "        features.extend(fit_features)\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])], test=df_test,x_features=features, y_feature=pop)\n",
    "        \n",
    "        print('\\nlinear regression - all as one model')\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])], test=df_test,x_features=[rank, 'Y_year', 'log_weeks_on_charts', 'log_jump_time', 'log_max_jump_duration','new_feature'], y_feature=pop)\n",
    "        \n",
    "        print('\\nlinear regression - sum all feature model')\n",
    "        evaluation_featured_model(train=df_train[df_train.year.isin([start_year, end_year])], test=df_test,x_features=[rank, 'Y_year', 'log_weeks_on_charts', 'log_jump_time', 'log_max_jump_duration','sum_feature'], y_feature=pop)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.loc[(df_train['songs-used-in-commercials'] == 1)].shape[0])\n",
    "print(df_train.loc[(df_train['songs-used-in-movies'] == 1)].shape[0])\n",
    "print(df_train.loc[(df_train['songs-used-in-tv-shows'] == 1)].shape[0])\n",
    "print(df_train.loc[(df_train['songs-used-in-movies'] == 1) |\\\n",
    "                   (df_train['songs-used-in-tv-shows'] == 1) |\\\n",
    "                   (df_train['songs-used-in-commercials'] == 1)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_train[list(df_features.keys())].corr()\n",
    "corr.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [rank, 'Y_year', 'log_weeks_on_charts', 'log_jump_time', 'log_max_jump_duration']\n",
    "features.extend(fit_features)\n",
    "features.remove('fit-songs-for-wedding-anniversaries')\n",
    "corr = df_train[features].corr()\n",
    "corr.style.background_gradient()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
